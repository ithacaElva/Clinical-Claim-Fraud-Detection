{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Kaggletest.ipynb","provenance":[],"authorship_tag":"ABX9TyMyAzLxRtXOEnDqLtcG2Yaq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":512},"id":"YcaQfxAfpC5-","executionInfo":{"status":"error","timestamp":1638393810497,"user_tz":300,"elapsed":6536,"user":{"displayName":"Xin Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11856198583513570372"}},"outputId":"1a58c84e-09ff-4756-c18d-be2687bfc518"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \"\"\"\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0muse_metadata_server\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_metadata_server\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m       ephemeral=ephemeral)\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server, ephemeral)\u001b[0m\n\u001b[1;32m    290\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"OoVd4A7UAFYY"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn import preprocessing\n","import seaborn as sns\n"," \n","from sklearn.model_selection import train_test_split, ShuffleSplit, learning_curve, GridSearchCV, KFold, StratifiedKFold\n","from sklearn.linear_model import LogisticRegression, Perceptron\n","from sklearn.metrics import roc_curve, accuracy_score, confusion_matrix, classification_report, roc_auc_score, make_scorer, precision_recall_curve, average_precision_score \n","from sklearn.svm import SVC\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import cross_val_score, cross_val_predict\n","from sklearn import metrics"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GaqFWJqZhuaT"},"source":["def N_unique_values(df):\n","    return np.array([len(set([i for i in x[~pd.isnull(x)]])) for x in df.values])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ma8mkuAjDqZ4"},"source":["!pip install catboost"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x2uwJ8cKD6PJ"},"source":["!pip install shap"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hN0xr8kFDlpK"},"source":["from sklearn.ensemble import RandomForestClassifier, IsolationForest, VotingClassifier\n","from sklearn.neural_network import MLPClassifier\n","\n","%matplotlib inline\n","plt.style.use('ggplot')\n","\n","from catboost import CatBoostClassifier # Or CatBoostRegressor\n","from sklearn.model_selection import KFold\n","from itertools import product,chain\n","\n","import shap\n","import catboost\n","from catboost import *\n","from sklearn.naive_bayes import GaussianNB\n","\n","from sklearn.metrics import recall_score, accuracy_score, confusion_matrix, classification_report\n","import random\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","\n","np.random.seed(0)\n","random.seed(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m1Bv7CAGD4-T"},"source":["from sortedcontainers import SortedList\n","import copy\n","import collections\n","import numpy as np\n","from itertools import product,chain\n","import pandas\n","from sklearn.model_selection import KFold\n","import catboost as cb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YUqMgzqjDly9"},"source":["class paramsearch:\n","    def __init__(self,pdict):    \n","        self.pdict = {}\n","        # if something is not passed in as a sequence, make it a sequence with 1 element\n","        #   don't treat strings as sequences\n","        for a,b in pdict.items():\n","            if isinstance(b, collections.Sequence) and not isinstance(b, str): self.pdict[a] = b\n","            else: self.pdict[a] = [b]\n","        # our results are a sorted list, so the best score is always the final element\n","        self.results = SortedList()       \n","                    \n","    def grid_search(self,keys=None):\n","        # do grid search on only the keys listed. If none provided, do all\n","        if keys==None: keylist = self.pdict.keys()\n","        else: keylist = keys\n","        listoflists = [] # this will be list of lists of key,value pairs\n","        for key in keylist: listoflists.append([(key,i) for i in self.pdict[key]])\n","        for p in product(*listoflists):\n","            # do any changes to the current best parameter set\n","            if len(self.results)>0: template = self.results[-1][1]\n","            else: template = {a:b[0] for a,b in self.pdict.items()}\n","            # if our updates are the same as current best, don't bother\n","            if self.equaldict(dict(p),template): continue\n","            # take the current best and update just the ones to change\n","            yield self.overwritedict(dict(p),template)\n","                              \n","    def equaldict(self,a,b):\n","        for key in a.keys(): \n","            if a[key] != b[key]: return False\n","        return True            \n","\n","    def overwritedict(self,new,old):\n","        old = copy.deepcopy(old)\n","        for key in new.keys(): old[key] = new[key]\n","        return old            \n","    \n","    # save a (score,params) pair to results. Since 'results' is a sorted list,\n","    #   the best score is always the final element. A small amount of noise is added\n","    #   because sorted lists don't like it when two scores are exactly the same    \n","    def register_result(self,result,params):\n","        self.results.add((result+np.random.randn()*1e-10,params))    \n","        \n","    def bestscore(self):\n","        return self.results[-1][0]\n","        \n","    def bestparam(self):\n","        return self.results[-1][1]\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DLTOLHK7pyTg"},"source":["#Read data"]},{"cell_type":"code","metadata":{"id":"N3PxIBWOp05U"},"source":["# Function to load the inputs dataset\n","def read_data(tp = \"Train\", N = 1542865627584):\n","    target = pd.read_csv(\"/content/drive/MyDrive/Data/Kaggledata/train/Train-1542865627584.csv\".format(tp.title(), N))\n","    pt = pd.read_csv(\"/content/drive/MyDrive/Data/Kaggledata/train/Train_Beneficiarydata-1542865627584.csv\".format(tp.title(), N))\n","    in_pt = pd.read_csv(\"/content/drive/MyDrive/Data/Kaggledata/train/Train_Inpatientdata-1542865627584.csv\".format(tp.title(), N))\n","    out_pt = pd.read_csv(\"/content/drive/MyDrive/Data/Kaggledata/train/Train_Outpatientdata-1542865627584.csv\".format(tp.title(), N))\n","    return (in_pt, out_pt, pt, target)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3PHgiI7xAAIO"},"source":["in_pt, out_pt, ben, target = read_data()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bvHBy-v7B9jo"},"source":["ben"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FZtUXt0QBoko"},"source":["#Data Cleaning"]},{"cell_type":"code","metadata":{"id":"_sgNOrNNBrFl"},"source":["# Replace values with a binary annotation\n","ben = ben.replace({'ChronicCond_Alzheimer': 2, 'ChronicCond_Heartfailure': 2, 'ChronicCond_KidneyDisease': 2,\n","                   'ChronicCond_Cancer': 2, 'ChronicCond_ObstrPulmonary': 2, 'ChronicCond_Depression': 2,\n","                   'ChronicCond_Diabetes': 2, 'ChronicCond_IschemicHeart': 2, 'ChronicCond_Osteoporasis': 2,\n","                   'ChronicCond_rheumatoidarthritis': 2, 'ChronicCond_stroke': 2, 'Gender': 2 }, \n","                  0)\n","ben = ben.replace({'RenalDiseaseIndicator': 'Y'}, 1).astype({'RenalDiseaseIndicator': 'int64'})\n","\n","# Change target variable to binary\n","target[\"target\"] = np.where(target.PotentialFraud == \"Yes\", 1, 0) \n","target.drop('PotentialFraud', axis=1, inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6nZ899FZCoa4"},"source":["# Merge in_pt, out_pt and ben df into a single patient dataset\n","data = pd.merge(in_pt, out_pt,\n","                    left_on = [ idx for idx in out_pt.columns if idx in in_pt.columns],\n","                    right_on = [ idx for idx in out_pt.columns if idx in in_pt.columns],\n","                    how = 'outer').\\\n","          merge(ben,left_on='BeneID',right_on='BeneID',how='inner')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PqLZGcDzCrCf"},"source":["data"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tv7y4YVmC0ry"},"source":["patient_merge_id = [i for i in out_pt.columns if i in in_pt.columns]\n","\n","# Merge in_pt, out_pt and ben df into a single patient dataset\n","data = pd.merge(in_pt, out_pt,\n","                    left_on = patient_merge_id,\n","                    right_on = patient_merge_id,\n","                    how = 'outer').\\\n","          merge(ben,left_on='BeneID',right_on='BeneID',how='inner')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zReNNDXNC4Rv"},"source":["data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kf8Ky9C1DAL4"},"source":["#Feature Engineering"]},{"cell_type":"code","metadata":{"id":"9-HbuYzFC-B4"},"source":["# We find the number of unique physicians \n","data['N_unique_Physicians'] = N_unique_values(data[['AttendingPhysician', 'OperatingPhysician', 'OtherPhysician']]) \n","\n","# We separate the types of physicians into numeric values\n","data[['AttendingPhysician', 'OperatingPhysician', 'OtherPhysician']] = np.where(data[['AttendingPhysician','OperatingPhysician',\n","                                                                                      'OtherPhysician']].isnull(), 0, 1)\n","\n","# We count the number of types of physicians that attend the patient\n","data['N_Types_Physicians'] = data['AttendingPhysician'] +  data['OperatingPhysician'] + data['OtherPhysician']\n","\n","# Now we create a variable to check if there is a single doctor on a patient that was attended by more than 1 type of doctor\n","# This helps us finds those cases that are only looked at by 1 physicians\n","data['Same_Physician'] = data.apply(lambda x: 1 if (x['N_unique_Physicians'] == 1 and x['N_Types_Physicians'] > 1) else 0,axis=1)\n","\n","# Similar to Same_Physician, we create a variable to see if 1 physicians has had multiple roles, but has not been alone reviewing the case\n","data['Same_Physician2'] = data.apply(lambda x: 1 if (x['N_unique_Physicians'] == 2 and x['N_Types_Physicians'] > 2) else 0,axis=1)\n","\n","# We check our new variables\n","data[['N_unique_Physicians','N_Types_Physicians','Same_Physician','Same_Physician2']].head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O3Bg-izOC-LL"},"source":["# We count the number of procedures for each claim, we drop the initial variables\n","ClmProcedure_vars = ['ClmProcedureCode_{}'.format(x) for x in range(1,7)]\n","data['N_Procedure'] = N_unique_values(data[ClmProcedure_vars])\n","data = data.drop(ClmProcedure_vars, axis = 1)\n","\n","# We count the number of claims, we also separate this by unique claims and extra claims, we drop the initial variables\n","ClmDiagnosisCode_vars =['ClmAdmitDiagnosisCode'] + ['ClmDiagnosisCode_{}'.format(x) for x in range(1, 11)]\n","\n","data['N_Unique_Claims'] = N_unique_values(data[ClmDiagnosisCode_vars])\n","data['N_Total_Claims'] = data[ClmDiagnosisCode_vars].notnull().to_numpy().sum(axis = 1)\n","data['N_Extra_Claims'] = data['N_Total_Claims'] - data['N_Unique_Claims']\n","\n","ClmDiagnosisCode_vars.append('N_Total_Claims')\n","data = data.drop(ClmDiagnosisCode_vars, axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PXAF4uO4iq60"},"source":["#  Transform string columns of date into type date\n","data['AdmissionDt'] = pd.to_datetime(data['AdmissionDt'] , format = '%Y-%m-%d')\n","data['DischargeDt'] = pd.to_datetime(data['DischargeDt'],format = '%Y-%m-%d')\n","\n","data['ClaimStartDt'] = pd.to_datetime(data['ClaimStartDt'] , format = '%Y-%m-%d')\n","data['ClaimEndDt'] = pd.to_datetime(data['ClaimEndDt'],format = '%Y-%m-%d')\n","\n","data['DOB'] = pd.to_datetime(data['DOB'] , format = '%Y-%m-%d')\n","data['DOD'] = pd.to_datetime(data['DOD'],format = '%Y-%m-%d')\n","\n","# Number of days\n","data['Admission_Days'] = ((data['DischargeDt'] - data['AdmissionDt']).dt.days) + 1\n","\n","# Number of claim days \n","data['Claim_Days'] = ((data['ClaimEndDt'] - data['ClaimStartDt']).dt.days) + 1\n","\n","# Age at the time of claim\n","data['Age'] = round(((data['ClaimStartDt'] - data['DOB']).dt.days + 1)/365.25)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FVGDy-NXixGm"},"source":["# We create a Hospitalization flag \n","data['Hospt'] = np.where(data.DiagnosisGroupCode.notnull(), 1, 0)\n","data = data.drop(['DiagnosisGroupCode'], axis = 1)\n","\n","# Variable if patient is dead\n","data['Dead']= 0\n","data.loc[data.DOD.notna(),'Dead'] = 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jRkrN95Hizbm"},"source":["#Handling Miss Data"]},{"cell_type":"code","metadata":{"id":"I5Fd8XlMi3Ch"},"source":["# We find which variables hold missing data\n","na = data.isnull().sum()\n","na[na != 0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s0FepV2bjBH6"},"source":["## We know that missing admission days come from missing admission and discharge date, and those cases come from the out patients data set\n","\n","\n","# We also see that there are some cases of missing deductible amount paid, so we also want to keep an eye on that\n","data['Missing_Deductible_Amount_Paid'] = 0\n","data.loc[data['DeductibleAmtPaid'].isnull(), 'Missing_Deductible_Amount_Paid'] = 1 \n","\n","# After identifying the missing values, we fill the missing values with 0\n","data = data.fillna(0).copy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n3LJwB1opnOQ"},"source":["data"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kLuknxozjGZO"},"source":["#Create Final Dataset"]},{"cell_type":"code","metadata":{"id":"GTvdQDZEjE8i"},"source":["### Sum all numeric variables\n","_sum = data.groupby(['Provider'], as_index = False)[['InscClaimAmtReimbursed', 'DeductibleAmtPaid', 'RenalDiseaseIndicator', \n","                                                    'ChronicCond_Alzheimer', 'AttendingPhysician', 'OperatingPhysician', \n","                                                    'OtherPhysician', 'N_unique_Physicians', 'ChronicCond_Heartfailure', \n","                                                    'N_Types_Physicians', 'Same_Physician',\n","                                                    'ChronicCond_KidneyDisease', 'ChronicCond_Cancer', \n","                                                    'ChronicCond_ObstrPulmonary', 'ChronicCond_Depression', \n","                                                    'ChronicCond_Diabetes', 'ChronicCond_IschemicHeart', \n","                                                    'ChronicCond_Osteoporasis', 'ChronicCond_rheumatoidarthritis',\n","                                                    'ChronicCond_stroke', 'Dead', \n","                                                    'N_Procedure','N_Unique_Claims', 'N_Extra_Claims', 'Admission_Days',\n","                                                    'Claim_Days', 'Hospt', 'Missing_Deductible_Amount_Paid']].sum()\n","\n","# To separate our variables, we shall add '_sum' at the end of their names\n","_sum = _sum.add_suffix('_sum')\n","\n","\n","### Count number of records\n","_count = data[['BeneID', 'ClaimID']].groupby(data['Provider']).nunique().reset_index()\n","_count.rename(columns={'BeneID':'BeneID_count','ClaimID':'ClaimID_count'},inplace=True)\n","\n","### Calculate mean for all numeric variables\n","_mean = data.groupby(['Provider'], as_index = False)[['NoOfMonths_PartACov', 'NoOfMonths_PartBCov',\n","                                                      'IPAnnualReimbursementAmt', 'IPAnnualDeductibleAmt',\n","                                                      'OPAnnualReimbursementAmt', 'OPAnnualDeductibleAmt', 'Age',\n","                                                      'AttendingPhysician', 'OperatingPhysician','OtherPhysician',\n","                                                      'N_unique_Physicians', 'ChronicCond_Heartfailure', \n","                                                      'N_Types_Physicians', 'Same_Physician',\n","                                                      'ChronicCond_KidneyDisease', 'ChronicCond_Cancer', \n","                                                      'ChronicCond_ObstrPulmonary', 'ChronicCond_Depression', \n","                                                      'ChronicCond_Diabetes', 'ChronicCond_IschemicHeart', \n","                                                      'ChronicCond_Osteoporasis', 'ChronicCond_rheumatoidarthritis',\n","                                                      'ChronicCond_stroke', 'Dead', 'N_Procedure','N_Unique_Claims', \n","                                                      'N_Extra_Claims', 'Admission_Days','Claim_Days', 'Hospt',\n","                                                      'Missing_Deductible_Amount_Paid']].mean()\n","\n","# To separate our variables, we shall add '_mean' at the end of their names\n","_mean = _mean.add_suffix('_mean')\n","\n","# We create a dataset that holds all the variables\n","_total = _count.merge(_sum, how='left',left_on='Provider',right_on='Provider_sum').\\\n","                merge(_mean, how='left',left_on='Provider',right_on='Provider_mean').\\\n","                drop(['Provider_sum','Provider_mean'], axis=1).\\\n","                merge(target, on='Provider', how='left')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B2nMXBPbjd51"},"source":["_total.groupby( [\"target\"] ).target.count().plot(kind = \"bar\", figsize = (10,6));"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rnAqJKRojlDF"},"source":["#Feature Selection - Correlation"]},{"cell_type":"code","metadata":{"id":"V1TEXlkYjfNx"},"source":["def plot_corr(df_corr):\n","    corrMatrix = df_corr.corr()\n","    plt.subplots(figsize=(20,15))\n","    sns.heatmap(corrMatrix, annot=False)\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rH44cuBtjsgF"},"source":["# We plot the correlations in the _sum dataset\n","plot_corr(_sum)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KtV2b1NBjv87"},"source":["# We drop correlated values \n","sum_corr = _sum.drop(['Hospt_sum','AttendingPhysician_sum','OperatingPhysician_sum','Admission_Days_sum',\n","                      'OtherPhysician_sum','ChronicCond_ObstrPulmonary_sum', 'ChronicCond_Depression_sum',\n","                      'ChronicCond_Diabetes_sum','ChronicCond_IschemicHeart_sum','ChronicCond_KidneyDisease_sum', \n","                      'ChronicCond_Cancer_sum','ChronicCond_Osteoporasis_sum','RenalDiseaseIndicator_sum',\n","                      'ChronicCond_rheumatoidarthritis_sum','ChronicCond_Heartfailure_sum','N_Unique_Claims_sum',\n","                      'ChronicCond_Alzheimer_sum','ChronicCond_stroke_sum','N_Procedure_sum','N_unique_Physicians_sum',\n","                      'N_Types_Physicians_sum','DeductibleAmtPaid_sum'],axis=1) \n","\n","# And plot again to check\n","plot_corr(sum_corr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EOqPEaoHj1g-"},"source":["# We plot the correlations in the _mean dataset\n","plot_corr(_mean)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EErI3D0zkQ8G"},"source":["# We drop correlated values \n","mean_corr = _mean.drop(['Hospt_mean','Admission_Days_mean','N_unique_Physicians_mean','NoOfMonths_PartBCov_mean',\n","                        'NoOfMonths_PartACov_mean','IPAnnualReimbursementAmt_mean','N_Procedure_mean',\n","                        'OPAnnualDeductibleAmt_mean', 'N_Unique_Claims_mean'], axis=1) \n","\n","# And plot again to check\n","plot_corr(mean_corr)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UYEyxY5zkfWH"},"source":["#Unsupervised Model "]},{"cell_type":"code","metadata":{"id":"bDQoMVoTraIq"},"source":["!pip install pyod"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZXwHeBIUkky0"},"source":["from pyod.models.pca import PCA"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2XrKqdo_rx0y"},"source":["clf_mean_PCA = PCA()\n","clf_mean_PCA\n","#_mean, _sum\n","clf_mean_PCA.fit(_mean.iloc[:,1:31])\n","label_mean_PCA = clf_mean_PCA.predict(_mean.iloc[:,1:31], return_confidence=False)\n","label_mean_PCA #541"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"elTseg96uYre"},"source":["from pyod.models.iforest import "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1vBQz5pGtzxe"},"source":["clf_mean_IForest = IForest()\n","clf_mean_IForest\n","#_mean, _sum\n","clf_mean_IForest.fit(_mean.iloc[:,1:31])\n","label_mean_IForest = clf_mean_IForest.predict(_mean.iloc[:,1:31], return_confidence=False)\n","label_mean_IForest #541"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"71j_Or5Nu4Pl"},"source":["from pyod.models.auto_encoder import AutoEncoder\n","clf_mean_AE = AutoEncoder(epochs=30, hidden_neurons =[2, 1, 1, 2])\n","clf_mean_AE\n","#_mean, _sum\n","clf_mean_AE.fit(_mean.iloc[:,1:31])\n","label_mean_AE = clf_mean_AE.predict(_mean.iloc[:,1:31], return_confidence=False)\n","label_mean_AE #541"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JeRow4d1tX2L"},"source":["#Combine label with data"]},{"cell_type":"code","metadata":{"id":"45jY4XZHtR9U"},"source":["mean_data_PCA = pd.concat([_mean, pd.DataFrame(label_mean_PCA)],axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gf-RUpOQtW1W"},"source":["mean_data_IForest = pd.concat([_mean, pd.DataFrame(label_mean_IForest)],axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mSXLlW3BvVRi"},"source":["mean_data_AE = pd.concat([_mean, pd.DataFrame(label_mean_AE)],axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hdqlF_4xvZam"},"source":["combined = pd.concat([_mean, pd.DataFrame(label_mean_PCA), pd.DataFrame(label_mean_IForest), pd.DataFrame(label_mean_AE)],axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c3PRUrfHvhYW"},"source":["label_combined = combined.iloc[:,32:35].sum(axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-s5-yGHhwqvu"},"source":["label_combined"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q-Y-fobsxXUB"},"source":["from collections import Counter"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OgTXlmtPyE-D"},"source":["Counter(label_combined)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TorLb4qt-hy3"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aPoL_M1my5A1"},"source":["#和真实label比较"]},{"cell_type":"code","metadata":{"id":"jIy9c9F5y39j"},"source":["#mean_data_PCA，mean_data_IForest，mean_data_AE"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PF1aZ6FkOD5j"},"source":["label_comp = pd.concat([_total['target'],pd.DataFrame(label_mean_PCA), pd.DataFrame(label_mean_IForest), pd.DataFrame(label_mean_AE), label_combined],axis =1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C3Roj6UgPYZb"},"source":["label_comp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YQ6ClaEKPVwA"},"source":["#PCA:\n","print(sum(label_comp.iloc[:,0] == label_comp.iloc[:,1]) / len(label_comp.iloc[:,0]))\n","print(sum(label_comp.iloc[:,0] + label_comp.iloc[:,1] == 2) / sum(label_comp.iloc[:,0]==1))\n","print(sum(label_comp.iloc[:,0]==1))\n","print(sum(label_comp.iloc[:,1] == 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WIgrCDKOPc_C"},"source":["#IF\n","print(sum(label_comp.iloc[:,0] == label_comp.iloc[:,2]) / len(label_comp.iloc[:,0]))\n","print(sum(label_comp.iloc[:,0] + label_comp.iloc[:,2] == 2) / sum(label_comp.iloc[:,0]==1))\n","print(sum(label_comp.iloc[:,0]==1))\n","print(sum(label_comp.iloc[:,2] == 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IJMcYkmYPicX"},"source":["#IF\n","print(sum(label_comp.iloc[:,0] == label_comp.iloc[:,3]) / len(label_comp.iloc[:,0]))\n","print(sum(label_comp.iloc[:,0] + label_comp.iloc[:,3] == 2) / sum(label_comp.iloc[:,0]==1))\n","print(sum(label_comp.iloc[:,0]==1))\n","print(sum(label_comp.iloc[:,3] == 1))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xR69xof_8jaV"},"source":["#data.apply(lambda x: 1 if (x['N_unique_Physicians'] == 1 and x['N_Types_Physicians'] > 1) else 0,axis=1)\n","array = []\n","for i in range(len(label_comp.iloc[:,0])):\n","  if label_comp.iloc[i,4] >= 1:\n","    array.append(1)\n","  else:\n","    array.append(0)\n","label_comp1 = pd.concat([label_comp, pd.DataFrame(array)],axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XjVT3v4X9rlB"},"source":["#combined\n","print(sum(label_comp1.iloc[:,5] == label_comp1.iloc[:,0]) / len(label_comp1.iloc[:,0]))\n","print(sum(label_comp1.iloc[:,5] + label_comp1.iloc[:,0] == 2) / len(label_comp1.iloc[:,0]))\n","print(sum(label_comp1.iloc[:,5] + label_comp1.iloc[:,0] == 2) / sum(label_comp1.iloc[:,0]==1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AQ_vLa1zPBfw"},"source":["#XGBoost"]},{"cell_type":"markdown","metadata":{"id":"115Q3Oc_DRqs"},"source":["## Data set"]},{"cell_type":"code","metadata":{"id":"lmaEostgPA3J"},"source":["PCA_prob = clf_mean_PCA.predict_proba(_mean.iloc[:,1:31], method='linear', return_confidence=True)[0][:,0]\n","IF_prob = clf_mean_IForest.predict_proba(_mean.iloc[:,1:31], method='linear', return_confidence=True)[0][:,0]\n","AE_prob = clf_mean_AE.predict_proba(_mean.iloc[:,1:31], method='linear', return_confidence=True)[0][:,0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Viajty_RFoK7"},"source":["_total_ = _count.merge(_mean, how='left',left_on='Provider',right_on='Provider_mean').\\\n","                drop(['Provider_mean'], axis=1).\\\n","                merge(target, on='Provider', how='left')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4lFeYxN4DUO7"},"source":["total_su = pd.concat([_total_.iloc[:,1:34],pd.DataFrame(PCA_prob),pd.DataFrame(IF_prob),pd.DataFrame(AE_prob),_total_.iloc[:,-1]],axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KbpTcft1FxeF"},"source":["#total_su"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CVnFe3QiEelK"},"source":["plot_corr(total_su)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lWglmTezGoXu"},"source":["total_su"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TIssq-3hGYwV"},"source":["#total_su = pd.concat([total_su.iloc[:,0:35],total_su.iloc[:,36]],axis=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zX-oDW7jG5w8"},"source":["plot_corr(total_su)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qbA5-8uuHHAk"},"source":["##Shap Value"]},{"cell_type":"code","metadata":{"id":"sBaIPGMqHCdM"},"source":["#total_su\n","df = _total[['Provider','InscClaimAmtReimbursed_sum','N_Extra_Claims_sum','Claim_Days_sum',\n","             'AttendingPhysician_mean','Missing_Deductible_Amount_Paid_mean','Dead_mean','Claim_Days_mean','N_Extra_Claims_mean',\n","             'BeneID_count','ClaimID_count',\n","             'target']]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hsvZisipIoXN"},"source":["df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"044Evi24H_vu"},"source":["df_su = pd.concat([df.iloc[:,0:11],pd.DataFrame(PCA_prob),pd.DataFrame(IF_prob),df.iloc[:,11]], axis = 1)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sGJTVfWGHbHz"},"source":["## Model"]},{"cell_type":"markdown","metadata":{"id":"zHs9gKt0J58B"},"source":["### Carboost"]},{"cell_type":"code","metadata":{"id":"7ScKxrchJ8qF"},"source":["def cm_Score(model, df):\n","    recall = np.mean(cross_val_score(model, df.drop(['Provider','target'], axis = 1), df.target, cv=3, scoring='recall'))\n","    accuracy = np.mean(cross_val_score(model, df.drop(['Provider','target'], axis = 1), df.target, cv=3, scoring='accuracy'))\n","    \n","    print('Accuracy Score: {}'.format(accuracy))\n","    print('Recall Score: {}'.format(recall))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dfCTRcR5J9xu"},"source":["#model, X_train, X_test, y_train, y_test = fcatboost(df_su.drop(['Provider','target'], axis = 1), df_su.target)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gf4yu7FbI1Pl"},"source":["###Logistic regression"]},{"cell_type":"code","metadata":{"id":"qNc2rH8FHc7F"},"source":["def flogistic(df, penalty):\n","    X_train, X_test, y_train, y_test = train_test_split(df_su.drop(['Provider','target'], axis = 1),df.target, \n","                                                  test_size=0.30, random_state=1)\n","\n","    X_train = pd.DataFrame(StandardScaler().fit_transform(X_train))\n","    X_test = pd.DataFrame(StandardScaler().fit_transform(X_test))\n","    \n","    #Liblinear for small datasets of binary classes\n","    logreg = LogisticRegression(penalty= penalty,solver= 'liblinear',class_weight='balanced', random_state = 5 , C = 0.001)\n","    \n","    cm_Score(logreg, df_su)\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CDHl_6NzJASq"},"source":["flogistic(df_su, 'l1')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Ag4s6G3KaYV"},"source":["flogistic(df_su, 'l2')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NGc5C4ItKgpO"},"source":["##Naive Bayes"]},{"cell_type":"code","metadata":{"id":"v6EHL6QWKfoE"},"source":["def Gaus_bayes(df):\n","    X_train, X_test, y_train, y_test = train_test_split(df.drop(['Provider','target'], axis = 1),df.target, \n","                                                  test_size=0.30, random_state=1)\n","\n","\n","    X_train = pd.DataFrame(StandardScaler().fit_transform(X_train))\n","    X_test = pd.DataFrame(StandardScaler().fit_transform(X_test))\n","\n","    gnb = GaussianNB()\n","    \n","    cm_Score(gnb, df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VDxFoYbsKlUo"},"source":["Gaus_bayes(df_su)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G43ENlKFKseX"},"source":["##XGBoost"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4oZEjZne7g_z","executionInfo":{"status":"ok","timestamp":1638763736142,"user_tz":300,"elapsed":5411,"user":{"displayName":"Xin Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11856198583513570372"}},"outputId":"dca795a6-6892-415a-93ff-6f828a2628c0"},"source":["!pip install pyod"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyod\n","  Downloading pyod-0.9.5.tar.gz (113 kB)\n","\u001b[?25l\r\u001b[K     |██▉                             | 10 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 20 kB 28.1 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 30 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 40 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 51 kB 35.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 61 kB 37.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 71 kB 26.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 81 kB 27.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 92 kB 28.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 102 kB 30.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 112 kB 30.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 113 kB 30.4 MB/s \n","\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyod) (1.1.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pyod) (3.2.2)\n","Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.19.5)\n","Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.7/dist-packages (from pyod) (0.51.2)\n","Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.4.1)\n","Requirement already satisfied: scikit_learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from pyod) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pyod) (1.15.0)\n","Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod) (0.10.2)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod) (57.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit_learn>=0.20.0->pyod) (3.0.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (0.11.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (3.0.6)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pyod) (1.3.2)\n","Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod) (0.5.2)\n","Requirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod) (1.1.5)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19->statsmodels->pyod) (2018.9)\n","Building wheels for collected packages: pyod\n","  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyod: filename=pyod-0.9.5-py3-none-any.whl size=132699 sha256=971196f93257036ec77ebc868292fe1d8859efa28b5f2fef3ba0899652ad2429\n","  Stored in directory: /root/.cache/pip/wheels/3d/bb/b7/62b60fb451b33b0df1ab8006697fba7a6a49709a629055cf77\n","Successfully built pyod\n","Installing collected packages: pyod\n","Successfully installed pyod-0.9.5\n"]}]},{"cell_type":"code","metadata":{"id":"pG6ybBWgsL4n","executionInfo":{"status":"ok","timestamp":1638763739348,"user_tz":300,"elapsed":1997,"user":{"displayName":"Xin Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11856198583513570372"}}},"source":["from pyod.models.xgbod import XGBOD\n","from pyod.models.iforest import IForest\n","from pyod.models.pca import PCA"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"L93DPis2vV59","executionInfo":{"status":"ok","timestamp":1638763741858,"user_tz":300,"elapsed":144,"user":{"displayName":"Xin Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11856198583513570372"}}},"source":["estimators = [IForest(),PCA()]\n","clf_mean_XGBOD = XGBOD(estimator_list=estimators, standardization_flag_list=None, max_depth=3, learning_rate=0.1, \n","                       n_estimators=100, silent=True, objective='binary:logistic', booster='gbtree', n_jobs=1, nthread=None, \n","                       gamma=0, min_child_weight=1, max_delta_step=0, subsample=1, colsample_bytree=1, colsample_bylevel=1, \n","                       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, base_score=0.5, random_state=0,)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"OV1VvxNgvk6e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638763743704,"user_tz":300,"elapsed":249,"user":{"displayName":"Xin Li","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11856198583513570372"}},"outputId":"38d713dd-ff29-4c54-8a92-d0828d708ffd"},"source":["clf_mean_XGBOD"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["XGBOD(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","   colsample_bytree=1,\n","   estimator_list=[IForest(behaviour='old', bootstrap=False, contamination=0.1, max_features=1.0,\n","    max_samples='auto', n_estimators=100, n_jobs=1, random_state=None,\n","    verbose=0), PCA(contamination=0.1, copy=True, iterated_power='auto', n_components=None,\n","  n_selected_components=None, random_state=None, standardization=True,\n","  svd_solver='auto', tol=0.0, weighted=True, whiten=False)],\n","   gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n","   min_child_weight=1, n_estimators=100, n_jobs=1, nthread=None,\n","   objective='binary:logistic', random_state=0, reg_alpha=0, reg_lambda=1,\n","   scale_pos_weight=1, silent=True, standardization_flag_list=None,\n","   subsample=1)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"TujSf5tPv9zL"},"source":["X_train, X_test, y_train, y_test = train_test_split(df_su.drop(['Provider','target'], axis = 1),df.target, \n","                                                  test_size=0.30, random_state=1)\n","\n","X_train = pd.DataFrame(StandardScaler().fit_transform(X_train))\n","X_test = pd.DataFrame(StandardScaler().fit_transform(X_test))\n","#y_train = pd.DataFrame(StandardScaler().fit_transform(y_train))\n","#y_test = pd.DataFrame(StandardScaler().fit_transform(y_test))  \n","\n","#Liblinear for small datasets of binary classes\n","clf_mean_xgbod = clf_mean_XGBOD.fit(X_train,y_train)\n","predict_xgbod = clf_mean_xgbod.predict(X_test)\n","    \n","#cm_Score(clf_mean_XGBOD, df_su)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mvz3I6oQzaUi"},"source":["len(y_test),len(predict_xgbod)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OICB6Xsgwo39"},"source":["sum(y_test == predict_xgbod)/1623"],"execution_count":null,"outputs":[]}]}